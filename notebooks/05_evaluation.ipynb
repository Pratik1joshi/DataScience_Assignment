{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a804a5",
   "metadata": {},
   "source": [
    "# 05 - Model Evaluation & Comparison\n",
    "\n",
    "**Objective**: Comprehensive evaluation of both trained models.\n",
    "\n",
    "- ROC Curves\n",
    "- Confusion Matrices\n",
    "- Metric Comparison (accuracy, precision, recall, F1, AUC-ROC)\n",
    "- Feature Importance Analysis\n",
    "- Algorithm Complexity Analysis (Big-O)\n",
    "- Final Summary & Recommendations\n",
    "\n",
    "**Input**: Predictions & metrics from `04_model_training.ipynb`  \n",
    "**Output**: Evaluation plots saved to `outputs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05b8cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\programdata\\anaconda3\\envs\\spark_env\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.15.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/8.9 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 23.0 MB/s  0:00:00\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.3 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afcc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session & plotting ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Imports & Spark Session\n",
    "# ============================================================\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, confusion_matrix,\n",
    "    classification_report, precision_recall_curve\n",
    ")\n",
    "import json, os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ModelEvaluation\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "DATA_DIR = r'F:\\SOFTWARICA\\big-data-transport-analytics\\data\\processed'\n",
    "MODEL_DIR = os.path.join(DATA_DIR, 'models')\n",
    "OUTPUT_DIR = r'F:\\SOFTWARICA\\big-data-transport-analytics\\outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({'font.size': 11, 'figure.dpi': 120})\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Spark session & plotting ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression predictions: 6,803 rows\n",
      "Random Forest predictions:        6,803 rows\n",
      "\n",
      "Metrics loaded:\n",
      "  logistic_regression: accuracy=0.8540, AUC=0.8906\n",
      "  random_forest: accuracy=0.8584, AUC=0.8795\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Load Predictions & Metrics\n",
    "# ============================================================\n",
    "\n",
    "# Load metrics from training\n",
    "with open(os.path.join(MODEL_DIR, 'model_metrics.json'), 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'feature_metadata.json'), 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "TARGET = metadata['target']\n",
    "\n",
    "# Load predictions (saved as CSV from notebook 04)\n",
    "lr_pdf = pd.read_csv(os.path.join(DATA_DIR, 'lr_predictions.csv'))\n",
    "rf_pdf = pd.read_csv(os.path.join(DATA_DIR, 'rf_predictions.csv'))\n",
    "\n",
    "print(f\"Logistic Regression predictions: {len(lr_pdf):,} rows\")\n",
    "print(f\"Random Forest predictions:        {len(rf_pdf):,} rows\")\n",
    "\n",
    "print(f\"\\nMetrics loaded:\")\n",
    "for model, m in metrics.items():\n",
    "    print(f\"  {model}: accuracy={m['accuracy']:.4f}, AUC={m['auc_roc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7630342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/roc_curves.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_29528\\2299066960.py:31: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: ROC Curves - Both Models\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "# Logistic Regression ROC\n",
    "lr_fpr, lr_tpr, _ = roc_curve(lr_pdf[TARGET], lr_pdf['prob_1'])\n",
    "lr_auc = auc(lr_fpr, lr_tpr)\n",
    "ax.plot(lr_fpr, lr_tpr, 'b-', linewidth=2,\n",
    "        label=f'Logistic Regression (AUC = {lr_auc:.4f})')\n",
    "\n",
    "# Random Forest ROC\n",
    "rf_fpr, rf_tpr, _ = roc_curve(rf_pdf[TARGET], rf_pdf['prob_1'])\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "ax.plot(rf_fpr, rf_tpr, 'r-', linewidth=2,\n",
    "        label=f'Random Forest (AUC = {rf_auc:.4f})')\n",
    "\n",
    "# Diagonal (random)\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.4, label='Random (AUC = 0.5)')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves — Model Comparison', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.set_xlim([-0.02, 1.02])\n",
    "ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'roc_curves.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39dd63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/precision_recall_curves.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_29528\\911621262.py:27: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Precision-Recall Curves\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "lr_prec, lr_rec, _ = precision_recall_curve(lr_pdf[TARGET], lr_pdf['prob_1'])\n",
    "rf_prec, rf_rec, _ = precision_recall_curve(rf_pdf[TARGET], rf_pdf['prob_1'])\n",
    "\n",
    "ax.plot(lr_rec, lr_prec, 'b-', linewidth=2, label='Logistic Regression')\n",
    "ax.plot(rf_rec, rf_prec, 'r-', linewidth=2, label='Random Forest')\n",
    "\n",
    "# Baseline (proportion of positive class)\n",
    "pos_rate = lr_pdf[TARGET].mean()\n",
    "ax.axhline(y=pos_rate, color='k', linestyle='--', alpha=0.4,\n",
    "           label=f'Baseline ({pos_rate:.2f})')\n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curves — Model Comparison',\n",
    "             fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'precision_recall_curves.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/precision_recall_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c5c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/confusion_matrices.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_29528\\3888851330.py:23: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Confusion Matrices - Side by Side\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, pdf, title, color in [\n",
    "    (axes[0], lr_pdf, 'Logistic Regression', 'Blues'),\n",
    "    (axes[1], rf_pdf, 'Random Forest', 'Reds'),\n",
    "]:\n",
    "    cm = confusion_matrix(pdf[TARGET], pdf['prediction'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=color, ax=ax,\n",
    "                xticklabels=['Low Risk (0)', 'High Risk (1)'],\n",
    "                yticklabels=['Low Risk (0)', 'High Risk (1)'],\n",
    "                annot_kws={'size': 14})\n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('Actual', fontsize=12)\n",
    "    ax.set_title(f'{title}\\nConfusion Matrix', fontweight='bold', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrices.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e264cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "LOGISTIC REGRESSION - Detailed Classification Report\n",
      "=================================================================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Low Risk (0)       0.84      0.99      0.91      5224\n",
      "High Risk (1)       0.94      0.40      0.56      1579\n",
      "\n",
      "     accuracy                           0.85      6803\n",
      "    macro avg       0.89      0.69      0.73      6803\n",
      " weighted avg       0.87      0.85      0.83      6803\n",
      "\n",
      "=================================================================\n",
      "RANDOM FOREST - Detailed Classification Report\n",
      "=================================================================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Low Risk (0)       0.85      0.99      0.91      5224\n",
      "High Risk (1)       0.92      0.43      0.58      1579\n",
      "\n",
      "     accuracy                           0.86      6803\n",
      "    macro avg       0.88      0.71      0.75      6803\n",
      " weighted avg       0.87      0.86      0.84      6803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Classification Reports (sklearn)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"LOGISTIC REGRESSION - Detailed Classification Report\")\n",
    "print(\"=\" * 65)\n",
    "print(classification_report(\n",
    "    lr_pdf[TARGET], lr_pdf['prediction'],\n",
    "    target_names=['Low Risk (0)', 'High Risk (1)']\n",
    "))\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"RANDOM FOREST - Detailed Classification Report\")\n",
    "print(\"=\" * 65)\n",
    "print(classification_report(\n",
    "    rf_pdf[TARGET], rf_pdf['prediction'],\n",
    "    target_names=['Low Risk (0)', 'High Risk (1)']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "305a8ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/model_comparison.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_29528\\3603932419.py:36: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Metric Comparison Bar Chart\n",
    "# ============================================================\n",
    "\n",
    "compare_metrics = ['accuracy', 'f1', 'precision', 'recall', 'auc_roc']\n",
    "lr_vals = [metrics['logistic_regression'][m] for m in compare_metrics]\n",
    "rf_vals = [metrics['random_forest'][m] for m in compare_metrics]\n",
    "\n",
    "x = np.arange(len(compare_metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, lr_vals, width, label='Logistic Regression',\n",
    "               color='#3498db', alpha=0.85)\n",
    "bars2 = ax.bar(x + width/2, rf_vals, width, label='Random Forest',\n",
    "               color='#e74c3c', alpha=0.85)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, h + 0.005,\n",
    "                f'{h:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([m.replace('_', ' ').title() for m in compare_metrics])\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 1.12)\n",
    "ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5, label='_')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'model_comparison.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9885507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/training_time.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_29528\\3040688568.py:25: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Training Time Comparison\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "models = ['Logistic Regression', 'Random Forest']\n",
    "times = [\n",
    "    metrics['logistic_regression']['train_time'],\n",
    "    metrics['random_forest']['train_time']\n",
    "]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(models, times, color=colors, alpha=0.85, width=0.5)\n",
    "for bar, t in zip(bars, times):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "            f'{t:.2f}s', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Training Time (seconds)', fontsize=12)\n",
    "ax.set_title('Training Time Comparison', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_time.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/training_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca47c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ALGORITHM COMPLEXITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Dataset dimensions:\n",
      "  Training samples (n): 28,119\n",
      "  Test samples:         6,803\n",
      "  Feature dimensions (p): 35\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL 1: LOGISTIC REGRESSION\n",
      "----------------------------------------------------------------------\n",
      "  Training complexity:   O(n * p * iterations)\n",
      "                       = O(28,119 * 35 * 100)\n",
      "                       ≈ O(98,416,500) operations\n",
      "  Prediction complexity: O(p) per sample\n",
      "                       = O(35) per sample\n",
      "                       = O(35 * 6,803) = O(238,105) for full test set\n",
      "  Space complexity:      O(p) for model coefficients\n",
      "  Actual training time:  35.41s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL 2: RANDOM FOREST\n",
      "----------------------------------------------------------------------\n",
      "  Training complexity:   O(T * n * p * log(n))\n",
      "                       = O(100 * 28,119 * 35 * 14.8)\n",
      "                       ≈ O(1,454,522,812) operations\n",
      "  Prediction complexity: O(T * depth) per sample\n",
      "                       = O(100 * 10) = O(1000) per sample\n",
      "                       = O(1000 * 6,803) = O(6,803,000) for full test set\n",
      "  Space complexity:      O(T * 2^depth) = O(100 * 1024) = O(102,400) leaf nodes max\n",
      "  Actual training time:  52.24s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SCALABILITY COMPARISON\n",
      "----------------------------------------------------------------------\n",
      "  RF/LR training complexity ratio: 14.8x\n",
      "  Actual training time ratio:      1.5x\n",
      "\n",
      "  Logistic Regression scales linearly with data size.\n",
      "  Random Forest scales quasi-linearly (n * log(n)) per tree,\n",
      "  but the constant factor is 100 trees.\n",
      "\n",
      "  For real-time prediction:\n",
      "    LR:  35 multiplications + sigmoid  → sub-millisecond\n",
      "    RF:  100 tree traversals (depth ≤ 10)  → low milliseconds\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Algorithm Complexity Analysis (Big-O)\n",
    "# ============================================================\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'feature_metadata.json'), 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "n_train = meta['train_count']\n",
    "n_test = meta['test_count']\n",
    "p = meta['feature_vector_size']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ALGORITHM COMPLEXITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset dimensions:\")\n",
    "print(f\"  Training samples (n): {n_train:,}\")\n",
    "print(f\"  Test samples:         {n_test:,}\")\n",
    "print(f\"  Feature dimensions (p): {p}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"-\" * 70)\n",
    "import math\n",
    "lr_iters = 100\n",
    "print(f\"  Training complexity:   O(n * p * iterations)\")\n",
    "print(f\"                       = O({n_train:,} * {p} * {lr_iters})\")\n",
    "print(f\"                       ≈ O({n_train * p * lr_iters:,.0f}) operations\")\n",
    "print(f\"  Prediction complexity: O(p) per sample\")\n",
    "print(f\"                       = O({p}) per sample\")\n",
    "print(f\"                       = O({p} * {n_test:,}) = O({p * n_test:,}) for full test set\")\n",
    "print(f\"  Space complexity:      O(p) for model coefficients\")\n",
    "print(f\"  Actual training time:  {metrics['logistic_regression']['train_time']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"-\" * 70)\n",
    "T = 100\n",
    "d = 10\n",
    "log_n = math.log2(n_train)\n",
    "print(f\"  Training complexity:   O(T * n * p * log(n))\")\n",
    "print(f\"                       = O({T} * {n_train:,} * {p} * {log_n:.1f})\")\n",
    "print(f\"                       ≈ O({T * n_train * p * log_n:,.0f}) operations\")\n",
    "print(f\"  Prediction complexity: O(T * depth) per sample\")\n",
    "print(f\"                       = O({T} * {d}) = O({T * d}) per sample\")\n",
    "print(f\"                       = O({T * d} * {n_test:,}) = O({T * d * n_test:,}) for full test set\")\n",
    "print(f\"  Space complexity:      O(T * 2^depth) = O({T} * {2**d}) = O({T * 2**d:,}) leaf nodes max\")\n",
    "print(f\"  Actual training time:  {metrics['random_forest']['train_time']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"SCALABILITY COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "ratio = (T * n_train * p * log_n) / (n_train * p * lr_iters)\n",
    "print(f\"  RF/LR training complexity ratio: {ratio:.1f}x\")\n",
    "time_ratio = metrics['random_forest']['train_time'] / max(metrics['logistic_regression']['train_time'], 0.01)\n",
    "print(f\"  Actual training time ratio:      {time_ratio:.1f}x\")\n",
    "print(f\"\\n  Logistic Regression scales linearly with data size.\")\n",
    "print(f\"  Random Forest scales quasi-linearly (n * log(n)) per tree,\")\n",
    "print(f\"  but the constant factor is {T} trees.\")\n",
    "print(f\"\\n  For real-time prediction:\")\n",
    "print(f\"    LR:  {p} multiplications + sigmoid  → sub-millisecond\")\n",
    "print(f\"    RF:  {T} tree traversals (depth ≤ {d})  → low milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b157885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Metric  Logistic Regression  Random Forest\n",
      "            Accuracy             0.854035       0.858445\n",
      "            F1 Score             0.830140       0.838027\n",
      "Precision (weighted)             0.867036       0.866612\n",
      "   Recall (weighted)             0.854035       0.858445\n",
      "             AUC-ROC             0.890608       0.879546\n",
      "   Training Time (s)            35.410227      52.244971\n",
      "\n",
      "Saved: outputs/model_comparison.csv\n",
      "Saved: outputs/rf_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Save Final Comparison CSV & Export Predictions\n",
    "# ============================================================\n",
    "\n",
    "# Model comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1 Score', 'Precision (weighted)',\n",
    "               'Recall (weighted)', 'AUC-ROC', 'Training Time (s)'],\n",
    "    'Logistic Regression': [\n",
    "        metrics['logistic_regression']['accuracy'],\n",
    "        metrics['logistic_regression']['f1'],\n",
    "        metrics['logistic_regression']['precision'],\n",
    "        metrics['logistic_regression']['recall'],\n",
    "        metrics['logistic_regression']['auc_roc'],\n",
    "        metrics['logistic_regression']['train_time'],\n",
    "    ],\n",
    "    'Random Forest': [\n",
    "        metrics['random_forest']['accuracy'],\n",
    "        metrics['random_forest']['f1'],\n",
    "        metrics['random_forest']['precision'],\n",
    "        metrics['random_forest']['recall'],\n",
    "        metrics['random_forest']['auc_roc'],\n",
    "        metrics['random_forest']['train_time'],\n",
    "    ],\n",
    "})\n",
    "comparison_df.to_csv(os.path.join(OUTPUT_DIR, 'model_comparison.csv'), index=False)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save RF predictions for further analysis\n",
    "rf_pdf.to_csv(os.path.join(OUTPUT_DIR, 'rf_predictions.csv'), index=False)\n",
    "\n",
    "print(f\"\\nSaved: outputs/model_comparison.csv\")\n",
    "print(f\"Saved: outputs/rf_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99faa273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL PROJECT SUMMARY\n",
      "Disruption Impact Risk Prediction for Ensign Bus\n",
      "======================================================================\n",
      "\n",
      "1. DATA PIPELINE\n",
      "   - Source: BODS TransXChange (170 XML files) + SIRI-SX (428 disruptions)\n",
      "   - Parsed: 34,922 timetable records with temporal disruption features\n",
      "   - Merge Strategy: Temporal (daily disruption metrics joined by date)\n",
      "   - Feature Engineering: 35 features after encoding & scaling\n",
      "\n",
      "2. MODELLING\n",
      "   - Task: Binary classification (high_disruption_risk: 0/1)\n",
      "   - Threshold: active_disruptions > 107.0\n",
      "   - Train/Test Split: 80/20 (seed=42)\n",
      "   - Model 1: Logistic Regression (baseline)\n",
      "   - Model 2: Random Forest Classifier (100 trees, depth 10)\n",
      "\n",
      "3. RESULTS\n",
      "   - Best Model: Logistic Regression\n",
      "   - Accuracy:   0.8540\n",
      "   - F1 Score:   0.8301\n",
      "   - AUC-ROC:    0.8906\n",
      "   - Precision:  0.8670\n",
      "   - Recall:     0.8540\n",
      "\n",
      "4. OUTPUT FILES\n",
      "   data/processed/\n",
      "     - ensign_timetable_with_disruptions.csv (merged dataset)\n",
      "     - cleaned_dataset.csv (cleaned)\n",
      "     - featured_dataset.csv (with target & features)\n",
      "     - lr_model/ & rf_model/ (saved PySpark models)\n",
      "     - model_metrics.json (all metrics)\n",
      "   outputs/\n",
      "     - roc_curves.png\n",
      "     - precision_recall_curves.png\n",
      "     - confusion_matrices.png\n",
      "     - model_comparison.png\n",
      "     - feature_importance.png\n",
      "     - training_time.png\n",
      "     - model_comparison.csv\n",
      "     - rf_predictions.csv\n",
      "\n",
      "5. NOTEBOOKS\n",
      "   01_data_ingestion.ipynb    → XML parsing, merge, CSV export\n",
      "   02_data_cleaning.ipynb     → Nulls, dupes, types, column selection\n",
      "   03_feature_engineering.ipynb → Target, EDA, PySpark pipeline\n",
      "   04_model_training.ipynb    → LR + RF training, feature importance\n",
      "   05_evaluation.ipynb        → ROC, confusion matrices, comparison\n",
      "\n",
      "======================================================================\n",
      "Project complete.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 11: Final Project Summary\n",
    "# ============================================================\n",
    "\n",
    "best_model = 'Random Forest' if metrics['random_forest']['auc_roc'] >= metrics['logistic_regression']['auc_roc'] else 'Logistic Regression'\n",
    "best_metrics = metrics['random_forest'] if best_model == 'Random Forest' else metrics['logistic_regression']\n",
    "\n",
    "print(\"=\"* 70)\n",
    "print(\"FINAL PROJECT SUMMARY\")\n",
    "print(\"Disruption Impact Risk Prediction for Ensign Bus\")\n",
    "print(\"=\"* 70)\n",
    "\n",
    "print(f\"\\n1. DATA PIPELINE\")\n",
    "print(f\"   - Source: BODS TransXChange (170 XML files) + SIRI-SX (428 disruptions)\")\n",
    "print(f\"   - Parsed: {n_train + n_test:,} timetable records with temporal disruption features\")\n",
    "print(f\"   - Merge Strategy: Temporal (daily disruption metrics joined by date)\")\n",
    "print(f\"   - Feature Engineering: {p} features after encoding & scaling\")\n",
    "\n",
    "print(f\"\\n2. MODELLING\")\n",
    "print(f\"   - Task: Binary classification (high_disruption_risk: 0/1)\")\n",
    "print(f\"   - Threshold: active_disruptions > {meta['threshold']}\")\n",
    "print(f\"   - Train/Test Split: 80/20 (seed=42)\")\n",
    "print(f\"   - Model 1: Logistic Regression (baseline)\")\n",
    "print(f\"   - Model 2: Random Forest Classifier (100 trees, depth 10)\")\n",
    "\n",
    "print(f\"\\n3. RESULTS\")\n",
    "print(f\"   - Best Model: {best_model}\")\n",
    "print(f\"   - Accuracy:   {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"   - F1 Score:   {best_metrics['f1']:.4f}\")\n",
    "print(f\"   - AUC-ROC:    {best_metrics['auc_roc']:.4f}\")\n",
    "print(f\"   - Precision:  {best_metrics['precision']:.4f}\")\n",
    "print(f\"   - Recall:     {best_metrics['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\n4. OUTPUT FILES\")\n",
    "print(f\"   data/processed/\")\n",
    "print(f\"     - ensign_timetable_with_disruptions.csv (merged dataset)\")\n",
    "print(f\"     - cleaned_dataset.csv (cleaned)\")\n",
    "print(f\"     - featured_dataset.csv (with target & features)\")\n",
    "print(f\"     - models/\")\n",
    "print(f\"         - lr_model_params.pkl & rf_model_params.pkl (model parameters)\")\n",
    "print(f\"         - feature_metadata.json (pipeline metadata)\")\n",
    "print(f\"         - model_metrics.json (all metrics)\")\n",
    "print(f\"   outputs/\")\n",
    "print(f\"     - roc_curves.png\")\n",
    "print(f\"     - precision_recall_curves.png\")\n",
    "print(f\"     - confusion_matrices.png\")\n",
    "print(f\"     - model_comparison.png\")\n",
    "print(f\"     - feature_importance.png\")\n",
    "print(f\"     - training_time.png\")\n",
    "print(f\"     - model_comparison.csv\")\n",
    "print(f\"     - rf_predictions.csv\")\n",
    "\n",
    "print(f\"\\n5. NOTEBOOKS\")\n",
    "print(f\"   01_data_ingestion.ipynb    → XML parsing, merge, CSV export\")\n",
    "print(f\"   02_data_cleaning.ipynb     → Nulls, dupes, types, column selection\")\n",
    "print(f\"   03_feature_engineering.ipynb → Target, EDA, PySpark pipeline\")\n",
    "print(f\"   04_model_training.ipynb    → LR + RF training, feature importance\")\n",
    "print(f\"   05_evaluation.ipynb        → ROC, confusion matrices, comparison\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"Project complete.\")\n",
    "print(f\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5103aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "# Stop Spark\n",
    "spark.stop()\n",
    "print(\"Spark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
